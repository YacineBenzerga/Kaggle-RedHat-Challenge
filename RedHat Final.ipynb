{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Load train and test set\n",
    "act_train = pd.read_csv('act_train.csv' , parse_dates=['date'])\n",
    "act_test = pd.read_csv('act_test.csv' , parse_dates=['date'])\n",
    "test_id = act_test['activity_id']\n",
    "ppl = pd.read_csv('people.csv' , parse_dates=['date'])\n",
    "train = act_train.merge(ppl , on='people_id' , how='left' , left_index=True)\n",
    "test = act_test.merge(ppl , on='people_id' , how='left' , left_index=True)\n",
    "del act_train , act_test , ppl\n",
    "train = train.sort_values(['people_id'] ,ascending=True)\n",
    "test = test.sort_values(['people_id'] , ascending=True)\n",
    "target = train['outcome']\n",
    "train.drop(['people_id' , 'activity_id' , 'outcome'],axis=1,inplace=True)\n",
    "\n",
    "#Train data Preprocess\n",
    "num_feat = list(train.dtypes[train.dtypes == ('int64' or 'float')].index)\n",
    "num_data = train[num_feat]\n",
    "cat_feat = list(train.dtypes[train.dtypes == ('object')].index)\n",
    "cat_data = train[cat_feat]\n",
    "bool_feat = list(train.dtypes[train.dtypes == ('bool')].index)\n",
    "bool_data = train[bool_feat] \n",
    "date_feat = ['date_x' , 'date_y']\n",
    "date_data = train[date_feat]\n",
    "missing_cat_feat = list(cat_data.isnull().sum().sort_values(ascending=False).head(10).index)\n",
    "cat_data.drop(missing_cat_feat , axis=1 , inplace=True)\n",
    "bool_data_bin = bool_data.apply(lambda x:x*1).astype(np.int64)\n",
    "\n",
    "for col in list(cat_data.columns):\n",
    "    cat_data[col].fillna('type 0', inplace=True)\n",
    "    \n",
    "for col in list(cat_data.columns):\n",
    "    cat_data[col] = cat_data[col].apply(lambda x:x.split(' ')[1]).astype(np.int64)\n",
    "    \n",
    "non_cat_data = pd.concat([bool_data_bin , num_data] , axis=1)\n",
    "train['time_diff'] = (train['date_x'] - train['date_y']).astype(str).apply(lambda x: x.split(' ')[0]).astype(np.int64) \n",
    "X_full = pd.concat([cat_data , non_cat_data , train['time_diff']],axis=1)\n",
    "print(X_full.shape)\n",
    "\n",
    "\n",
    "\n",
    "#Test data Preprocess\n",
    "test_id = test['activity_id']\n",
    "test.drop(['people_id' , 'activity_id'],axis=1,inplace=True)\n",
    "num_data_t= test[num_feat]\n",
    "cat_data_t= test[cat_feat]\n",
    "bool_data_t = test[bool_feat]\n",
    "date_data_t= test[date_feat]\n",
    "cat_data_t.drop(missing_cat_feat , axis=1 , inplace=True)\n",
    "bool_data_bin_t = bool_data_t.apply(lambda x:x*1).astype(np.int64)\n",
    "\n",
    "for col in list(cat_data_t.columns):\n",
    "    cat_data_t[col].fillna('type 0', inplace=True)\n",
    "\n",
    "for col in list(cat_data_t.columns):\n",
    "    cat_data_t[col] = cat_data_t[col].apply(lambda x:x.split(' ')[1]).astype(np.int64)\n",
    "    \n",
    "non_cat_data_t = pd.concat([bool_data_bin_t , num_data_t] , axis=1)\n",
    "test['time_diff'] = (test['date_x'] - test['date_y']).astype(str).apply(lambda x: x.split(' ')[0]).astype(np.int64)\n",
    "X_full_t = pd.concat([cat_data_t , non_cat_data_t , test['time_diff']],axis=1)\n",
    "print(X_full_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensionality Reduction\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "model_rf = rf.fit(X_full , target)\n",
    "model_rf = SelectFromModel(model_rf , prefit=True)\n",
    "X_full_red = model_rf.transform(X_full)\n",
    "print('reduced train data shape',X_full_red.shape)\n",
    "X_full_t_red = model_rf.transform(X_full_t)\n",
    "print('reduced test data shape' , X_full_t_red.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold , cross_val_score\n",
    "\n",
    "\n",
    "models = [('LR', LogisticRegression()) , \n",
    "          ('RF', RandomForestClassifier()), \n",
    "         ('AdaBoost', AdaBoostClassifier()),\n",
    "         ('MLP', MLPClassifier()),\n",
    "         ('Xgboost_classifier', XGBClassifier())]\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 7)\n",
    "\n",
    "for m in models:\n",
    "    this_score = cross_val_score(m[1] , X_full_red , target , scoring='roc_auc' , cv=skf , n_jobs=-1)\n",
    "    print('%s average AUC score is %.3f +/- %.3f' % (m[0],np.mean(this_score) , np.std(this_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameter tuning on XGBRegressor\n",
    "xgb = XGBClassifier()\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "param_grid_xgb = {'n_estimators':[20,35,50,100] , 'max_depth':[3,6,9]  ,'min_child_weight':[1,5,15]}\n",
    "grid_xgb = GridSearchCV(xgb , param_grid_xgb , cv=7 , scoring='roc_auc',n_jobs=-1)\n",
    "grid_xgb.fit(X_full_red,target)\n",
    "print('GS best score %.3f' % grid_xgb.best_score_)\n",
    "print('GS best params {}'.format(grid_xgb.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using best params to predict test data\n",
    "xgb_gs = grid_xgb.best_estimator_\n",
    "xgb_gs.fit(X_full_red , target)\n",
    "y_pred = xgb_gs.predict(X_full_t_red)\n",
    "solution = pd.DataFrame({'activity_id':test_id, 'outcome':y_pred})\n",
    "solution.to_csv('Redhat_xgb_gs.csv' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
